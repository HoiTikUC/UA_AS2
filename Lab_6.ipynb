{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de962d9b-68b4-4275-8391-e711dd88a47e",
   "metadata": {},
   "source": [
    "# Lab Workbook No 6: Geodemographics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932eb8d7-e72c-4f7b-b7fc-4dc02f9d6f1f",
   "metadata": {},
   "source": [
    "## Challenge 1: Geodemographic Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb7bd28-ace0-4ad8-b65c-5f52179ba7d4",
   "metadata": {},
   "source": [
    "The main goal of this geodemographic classification is to identify the vulnerable groups in Edinburgh for better service planning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0482847f-c61d-4b2d-b2e3-6291ce99ad35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Importing the shp file of the boundary of the \n",
    "# Scottish output area 2011 as a GeoDataFrame\n",
    "gdf = gpd.read_file(\n",
    "    \"/UA/Lab 6 Data /output-area-2011-mhw/OutputArea2011_MHW.shp\")\n",
    "\n",
    "# Subsetting the boundary of the City of Edinburgh from the .shp file \n",
    "# (with the value of S12000036 in the council column)\n",
    "EDI_ONLY_gdf = gdf[gdf[\"council\"] == \"S12000036\"]\n",
    "EDI_ONLY_gdf.to_file(\"EDI_ONLY.shp\")\n",
    "\n",
    "# Review the subset data frame\n",
    "EDI_ONLY_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f035c00b-d1d2-4290-960c-86de753d53dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# importing the Scotland 2011 census data \n",
    "csv_directory = \"/UA/Lab 6 Data /Census_raw_data\"\n",
    "\n",
    "# locate all .csv files and merge them into a single dataframe\n",
    "csv_files = [file for file in os.listdir(csv_directory) \n",
    "             if file.endswith(\".csv\")]\n",
    "\n",
    "merged_data = pd.DataFrame() # creating a empty dataframe\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    csv_path = os.path.join(csv_directory, csv_file) \n",
    "    df_csv = pd.read_csv(csv_path, low_memory=False) \n",
    "    merged_data = pd.concat([merged_data, df_csv], axis=1)\n",
    "    \n",
    "# Saving the merged data into the following address\n",
    "merged_data.to_csv(\"/UA/Lab 6 Data /merged_census_data.csv\", \n",
    "                   index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1da82c8-4ce0-4a45-aa47-123150f6f589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the census data with the City of Edinburgh output area boundary\n",
    "\n",
    "csv_path = \"/UA/Lab 6 Data /merged_census_data.csv\"\n",
    "csv_data = pd.read_csv(csv_path, low_memory=False)\n",
    "\n",
    "merged_data = EDI_ONLY_gdf.merge(csv_data, \n",
    "                                 left_on='code', \n",
    "                                 right_on='oa_code', \n",
    "                                 how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f410e63c-06ed-4667-b449-4bbaf2cc32e7",
   "metadata": {},
   "source": [
    "I have selected the four topics of Health, Economic activity, Central heating and Household composition structure to better illustrate which area is more vulnerable and requires more resources of public services. I have selected four variables that are crucial for effectively segmenting neighbourhoods, such as the elderly who lives alone, People in poor health condition, residents with no central heating, and unemployed but economically active people. These variables could directly address specific dimensions in both social and economic vulnerability, highlighting areas where people are at higher risk of isolation, health deterioration, or poor living conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bc4da5-9b4d-40c7-8bed-d2f2efdaeb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Selecting four variables and plotting all four graphs into one figure\n",
    "attributes_to_plot = ['One person household: Aged 65 and over',\n",
    "                      'Bad health',\n",
    "                      'No central heating',\n",
    "                      'Economically active: Unemployed']\n",
    "\n",
    "# Plotting a violin plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i, attribute in enumerate(attributes_to_plot, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    sns.violinplot(x=merged_data[attribute])\n",
    "    plt.title(attribute)\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cecd0b3-9823-47e9-819b-005f59fb0dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting four variables and plotting all four graphs into one figure\n",
    "attributes_to_plot = ['One person household: Aged 65 and over',\n",
    "                      'Bad health',\n",
    "                      'No central heating',\n",
    "                      'Economically active: Unemployed']\n",
    "\n",
    "# Plotting a histogram\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i, attribute in enumerate(attributes_to_plot, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    sns.histplot(merged_data[attribute].astype(str), kde=True)\n",
    "    plt.title(attribute)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16419067-f780-4cac-9218-b8ae07759a93",
   "metadata": {},
   "source": [
    "Now we prepare and clean the data for standardisation and clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f318e3-d5ac-497d-b668-8b1901a958af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the percentages of the selected variables\n",
    "\n",
    "# Setting up function to transform the data into percentages\n",
    "def calculate_percentages(dataframe, total_columns, value_columns):\n",
    "\n",
    "    result_df = pd.DataFrame() # empty dataframe for the processed data \n",
    "\n",
    "    for total_col, value_col in zip(total_columns, value_columns):\n",
    "        percentage_col_name = f\"{value_col}_percentage\"\n",
    "\n",
    "        if total_col not in dataframe.columns:\n",
    "            raise ValueError(\n",
    "                f\"Total column '{total_col}' not found in the DataFrame.\")\n",
    "            \n",
    "        # Turning any empty values into numeric or NaN value\n",
    "        dataframe[value_col] = pd.to_numeric(dataframe[value_col], \n",
    "                                             errors='coerce')\n",
    "        dataframe[total_col] = pd.to_numeric(dataframe[total_col], \n",
    "                                             errors='coerce')\n",
    "        \n",
    "        result_df[percentage_col_name] = (\n",
    "            dataframe[value_col] / dataframe[total_col]) * 100\n",
    "\n",
    "    return result_df\n",
    "\n",
    "# Selecting the right dominator\n",
    "total_cols = ['All households', # For Households composition \n",
    "              'All households',\n",
    "              'All people.3', # For Health\n",
    "              'All people.3',\n",
    "              'All people aged 16 to 74', # For Economic activity\n",
    "              'All people aged 16 to 74',\n",
    "              'All occupied household spaces', # For Central heating \n",
    "              'All occupied household spaces' ]\n",
    "\n",
    "# Selecting the variables that we are interested in\n",
    "# I also included contradictory variables \n",
    "# to the variables in the DEA analysis\n",
    "# It could capture a more complete and \n",
    "# accurate picture of neighborhood vulnerability\n",
    "value_cols = [\n",
    "'One family only: Married or same-sex civil partnership couple: With dependent children',\n",
    "              'One person household: Aged 65 and over',\n",
    "              'Bad health',\n",
    "              'Good health',\n",
    "              'Economically active: Unemployed',\n",
    "              'Economically active: Employee: Full-time',\n",
    "              'No central heating',\n",
    "              'Gas central heating']\n",
    "\n",
    "\n",
    "result_dataframe = calculate_percentages(merged_data, \n",
    "                                         total_cols, \n",
    "                                         value_cols)\n",
    "result_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0fd383-8fd6-47f6-b109-d00bb69411b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Concatenate date\n",
    "concatenated_df = pd.concat([merged_data, \n",
    "                             result_dataframe], \n",
    "                            axis=1, \n",
    "                            ignore_index=False)\n",
    "concatenated_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c8b3d0-3331-411e-baa3-3580f66256c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting the attributes to make it clear\n",
    "keep_cols= [\n",
    "    'code',\n",
    "    'Popcount',\n",
    "    'HHcount',\n",
    "    'DataZone',\n",
    "    'geometry',\n",
    "    'One family only: Married or same-sex civil partnership couple: With dependent children',\n",
    "    'One person household: Aged 65 and over',\n",
    "    'Bad health',\n",
    "    'Good health',\n",
    "    'Economically active: Unemployed',\n",
    "    'Economically active: Employee: Full-time',\n",
    "    'No central heating',\n",
    "    'Gas central heating'\n",
    "]\n",
    "\n",
    "EDI_SUB_data = concatenated_df[keep_cols]\n",
    "EDI_SUB_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592111f6-8ca0-4d84-8530-0c16b495e200",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_column_names = {\n",
    "\n",
    "'One family only: Married or same-sex civil partnership couple: With dependent children': \n",
    "    'ODC',\n",
    "    'One person household: Aged 65 and over': '65up',\n",
    "    'Bad health': 'B_H',\n",
    "    'Good health': 'G_H',\n",
    "    'Economically active: Unemployed': 'EA_U',\n",
    "    'Economically active: Employee: Full-time': 'EA_EF',\n",
    "    'No central heating': 'N_H',\n",
    "    'Gas central heating': 'Gs_H'\n",
    "}\n",
    "\n",
    "EDI_SUB_data = EDI_SUB_data.rename(columns=short_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9480fc-ec4f-4ff7-98ed-ec6cf95d6049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the data type\n",
    "EDI_SUB_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518f03b1-213f-4404-8948-8058c5dc226e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the columns turn out to be int64 \n",
    "# Now we have to switch it to float64\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# to ignore the warning for creating a copy\n",
    "warnings.filterwarnings(\"ignore\", \n",
    "                        category=pd.errors.SettingWithCopyWarning)\n",
    "\n",
    "cols_to_convert = ['G_H', 'N_H', 'Gs_H','65up']\n",
    "\n",
    "EDI_SUB_data[cols_to_convert] = EDI_SUB_data[\n",
    "cols_to_convert].replace('-',np.nan).astype('float64')\n",
    "\n",
    "print(EDI_SUB_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595cc9f6-69c2-43a9-82ae-aec2633cc9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Includes all numeric columns\n",
    "numeric_columns = EDI_SUB_data.select_dtypes(include='float64')\n",
    "\n",
    "# Convrt data into z score\n",
    "z_score_df = (numeric_columns - numeric_columns.mean()) / numeric_columns.std(ddof=0)\n",
    "z_score_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfa1485-a0be-4275-adf4-1de984424f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the correlation between attributes\n",
    "corr = z_score_df.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0f96b6-db43-4a21-8b43-b4ec17f77d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.matshow(z_score_df.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6e18aa-93a8-44bf-834e-8f018733358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for multicollinearity between variables\n",
    "# Once higher than the threshold, it counts as multicollinearity\n",
    "\n",
    "threshold = 0.7\n",
    "highly_correlated = (corr.abs() > threshold) & (corr.abs() < 1.0)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(highly_correlated, cmap='coolwarm', cbar=False, annot=True)\n",
    "plt.title('Highly Correlated Variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1db119-5822-4244-8420-e1cccf49a80c",
   "metadata": {},
   "source": [
    "No multicollinearity is observesd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428de3ae-592a-4e1b-a38c-c3246a8a5745",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for any NaN values\n",
    "contains_nan = z_score_df.isna().any().any()\n",
    "\n",
    "if contains_nan:\n",
    "    print(\"Contains NaN values....of course it does\")\n",
    "else:\n",
    "    print(\"No NaN values.That couldn't be true?!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01947cfb-62f8-450b-b82b-5085b402ef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN value with mean\n",
    "z_score_df.fillna(z_score_df.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4a78bd-6077-4a53-bc09-865f59e445c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3ae7e8-e5bd-4bf8-b5d5-718909c7d2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist, pdist\n",
    "\n",
    "# 10 clusters defined subjectivly \n",
    "kmeans = KMeans(n_clusters=10)\n",
    "kmeans.fit(z_score_df)\n",
    "labels = kmeans.predict(z_score_df)\n",
    "cluster_centres = kmeans.cluster_centers_\n",
    "z_score_df['Cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcc13ec-4efa-4f88-9144-59c29ce80de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6107b19d-0106-42be-9877-ec5141c4e322",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96edcada-df1a-4722-8d27-b9db1f226ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the Elbow Method for Optimal k\n",
    "Sum_of_squared_distances = []\n",
    "\n",
    "K_range = range(1,15)\n",
    "\n",
    "for k in K_range:\n",
    " km = KMeans(n_clusters=k)\n",
    " km = km.fit(z_score_df)\n",
    " Sum_of_squared_distances.append(km.inertia_)\n",
    "    \n",
    "plt.plot(K_range, Sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Sum_of_squared_distances')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a897bb94-b228-4a0d-9f2b-fba1d38aa4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def elbow(dataframe, n):\n",
    "    kMeansVar = [KMeans(n_clusters=k).fit(dataframe.values) for k in range(1, n)] \n",
    "    centroids = [X.cluster_centers_ for X in kMeansVar]\n",
    "    k_euclid = [cdist(dataframe.values, cent) for cent in centroids]\n",
    "    dist = [np.min(ke, axis=1) for ke in k_euclid]\n",
    "    wcss = [sum(d**2) for d in dist]\n",
    "    tss = sum(pdist(dataframe.values)**2)/dataframe.values.shape[0]\n",
    "    bss = tss - wcss\n",
    "    plt.plot(bss)\n",
    "    plt.show()\n",
    " \n",
    "elbow(z_score_df,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2010271f-5d23-4223-b9b1-c0a5b363ab8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the Optimal k as 6 by the Elbow method.\n",
    "\n",
    "kmeans = KMeans(n_clusters=6)\n",
    "kmeans.fit(z_score_df)\n",
    "labels = kmeans.predict(z_score_df)\n",
    "cluster_centres = kmeans.cluster_centers_\n",
    "\n",
    "z_score_df['Cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a9fede-3d3a-44a8-a425-dc2a1cf64d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "plt.figure(figsize=(8,12))\n",
    "\n",
    "kmeans = KMeans(n_clusters=6)\n",
    "clusters = kmeans.fit_predict(z_score_df)\n",
    "\n",
    "z_score_df['Cluster'] = clusters\n",
    "\n",
    "scaler = StandardScaler()\n",
    "stand_data_scaled = scaler.fit_transform(z_score_df)\n",
    "\n",
    "# Running the PCA and plotting a scatter plot\n",
    "pca = PCA(n_components=2).fit(stand_data_scaled)\n",
    "pca_result = pca.transform(stand_data_scaled)\n",
    "\n",
    "#Percentage of variance explained by each of the selected components.\n",
    "variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "\n",
    "fig = px.scatter(x=pca_result[:, 0], y=pca_result[:, 1], color=clusters,\n",
    "                 labels={'color': 'Cluster'},\n",
    "                 opacity=0.7,\n",
    "                 width=800, \n",
    "                 height=800)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.show()\n",
    "\n",
    "print(f\"These two components explain {(variance_ratio.sum()*100):.2f}% of the point variability.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b7e35f-efa8-4256-a3a6-d3b1f62b9553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examining the variability provided by each component.\n",
    "\n",
    "kmeans = KMeans(n_clusters=6)\n",
    "clusters = kmeans.fit_predict(z_score_df)\n",
    "\n",
    "z_score_df['Cluster'] = clusters\n",
    "\n",
    "# Standardize the data before conducting PCA\n",
    "scaler = StandardScaler()\n",
    "stand_data_scaled = scaler.fit_transform(z_score_df)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=2).fit(stand_data_scaled)\n",
    "pca_result = pca.transform(stand_data_scaled)\n",
    "\n",
    "#Percentage of variance explained by each of the selected components.\n",
    "variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=pca_result[:, 0], y=pca_result[:, 1], hue=clusters, palette='viridis', s=50, alpha=0.7)\n",
    "plt.title('Cluster Plot against 1st 2 Principal Components')\n",
    "plt.xlabel(f'Principal Component 1 variation: {variance_ratio[0]*100:.2f}%')\n",
    "plt.ylabel(f'Principal Component 2 variation: {variance_ratio[1]*100:.2f}%')\n",
    "plt.legend(title='Clusters')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c794723-8539-48ff-8c02-862019c6d4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMeans clustering\n",
    "kmeans = KMeans(n_clusters=6)\n",
    "clusters = kmeans.fit_predict(z_score_df)\n",
    "\n",
    "# Get the cluster centers\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "cluster_centers = pd.DataFrame(kmeans.cluster_centers_, columns=z_score_df.columns)\n",
    "\n",
    "cluster_centers.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7d4491-6465-4105-810e-c64faf76b29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "num_features = len(cluster_centers.columns)\n",
    "theta = np.linspace(0, 2 * np.pi, num_features, endpoint=True)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, subplot_kw={'projection': 'polar'}, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(6):\n",
    "    ax = axes[i]\n",
    "    center_values = cluster_centers.iloc[i, :].values\n",
    "\n",
    "    ax.plot(theta, center_values, linewidth=2, marker='o', label=f'Cluster {i}')\n",
    "    ax.fill(theta, center_values, alpha=0.25)\n",
    "    ax.plot(theta, np.zeros_like(center_values), color='red', linestyle='--', label='Average')\n",
    "\n",
    "    ax.set_xticks(theta)\n",
    "    ax.set_xticklabels(cluster_centers.columns, fontsize=9)\n",
    "\n",
    "    ax.legend(loc='upper right', fontsize=8)\n",
    "    ax.grid(True)\n",
    "\n",
    "\n",
    "plt.suptitle(\"\")  \n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac03deb-8d8a-4e64-bf7f-a30b0e8321af",
   "metadata": {},
   "source": [
    "Cluster 0: Unemployed Household in poor health condition\n",
    "Cluster 1: Best condition families with children dependent (with good health, central heating and a full-time job)\n",
    "Cluster 2: Average families with children dependent\n",
    "Cluster 3: Worst condition Household (both live-alone elderly and families with children) in poor health condition, without central heating and unemployed.\n",
    "Cluster 4: Families with children working full-time yet living without heating\n",
    "Cluster 5: Best condition Household (both live-alone elderly and families with children), with good health, central heating and a full-time job.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d3bd13-71ef-442d-a8b5-055bf709880b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(z_score_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1996d580-0635-4e09-9d42-01db75bce6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score_df.drop(['ODC', \n",
    "                 '65up', \n",
    "                 'B_H', \n",
    "                 'G_H', \n",
    "                 'EA_U', \n",
    "                 'EA_EF', \n",
    "                 'N_H', \n",
    "                 'Gs_H'], axis=1, inplace=True)\n",
    "z_score_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e7c0ca-2b8a-4df5-8036-f2babef03653",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([EDI_SUB_data, z_score_df], axis=1, ignore_index=False)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83222663-3683-47de-89ee-c494b0b39a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['Cluster'] = final_df['Cluster'].astype('category')\n",
    "\n",
    "# Use explore with categorical=True.\n",
    "final_df.explore(\n",
    "    column='Cluster',\n",
    "    cmap='Set1',\n",
    "    tiles='CartoDB positron',\n",
    "    categorical=True,\n",
    "    legend_kwds={'title': 'Cluster', 'labels': ['0', '1', '2', '3', '4', '5']}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0403e2-da07-4234-b583-c07e2519bbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['Cluster'] = final_df['Cluster'].astype(str)\n",
    "\n",
    "\n",
    "def rename_column(x): \n",
    "    x = x.replace(\"0\", \"Unwell & Unemployed\")\n",
    "    x = x.replace(\"1\", \"Comfortable Families\")\n",
    "    x = x.replace(\"2\", \"Ordinary Working Families\")\n",
    "    x = x.replace(\"3\", \"Vulnerable Households\")\n",
    "    x = x.replace(\"4\", \"Working but Energy-Poor\")\n",
    "    x = x.replace(\"5\", \"Healthy & Secure Households\")\n",
    "    # Add more values as you need. As many as clusters you have\n",
    "    return x\n",
    "\n",
    "final_df['Cluster'] = final_df['Cluster'].apply(rename_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d60fa5-d11f-4760-9678-8a89f5b05c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['Cluster'] = final_df['Cluster'].astype('category')\n",
    "\n",
    "\n",
    "final_df.explore(\n",
    "    column='Cluster',\n",
    "    cmap='Set1',\n",
    "    tiles='CartoDB positron',\n",
    "    categorical=True,\n",
    "    legend_kwds={'title': 'Cluster', 'labels': ['0', '1', '2', '3', '4', '5']}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baf7676-89ea-4df8-9abf-53a128d37edb",
   "metadata": {},
   "source": [
    "In service planning, this Geodemographic Classification helps identify the character of the target service user and indicate types of service that should be enhanced. For Cluster 0, the health condition and the unemployment situation would have to be addressed. Services such as health care allowance or employment programs have to be prioritized in consideration. Whereas, Cluster 1 is families with dependent children. Although they are rather well-off, services such as day care and education could still be improved for future development. The situation of Cluster 1 is quite similar to Cluster 3. As for Cluster 4, support in fostering living conditions could be considered. Last but not least, Cluster 5 is facing population aging; the current condition is rather secure, and service could focus on community connecting or building a nursing home.  Nonetheless, Cluster is not a clear-cut. The algorithm put each household into a single category. Yet in reality, households exist along a spectrum of socio-economic and environmental conditions. Furthermore, the choice of variables, number of clusters, and even the clustering method itself influence how these groupings emerge. Therefore, the application of cluster should be under careful consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cdd0aa-4c9a-4d43-92a1-eceab2951a32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
